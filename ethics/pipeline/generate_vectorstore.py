import os
import json
import pickle
import faiss
from sentence_transformers import SentenceTransformer

# ğŸ”§ ì„¤ì •
DATA_PATH = "/Users/chaewon/Desktop/STUBO/ethics/data/jsonl/parsing.jsonl"
INDEX_PATH = "/Users/chaewon/Desktop/STUBO/ethics/pipeline/index.faiss"
META_PATH = "/Users/chaewon/Desktop/STUBO/ethics/pipeline/questions_metadata.pkl"
MODEL_NAME = "jhgan/ko-sbert-nli"

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
with open(DATA_PATH, "r", encoding="utf-8") as f:
    raw_data = [json.loads(line) for line in f]

# 2. ë¬¸í•­ë³„ ì„ë² ë”© í…ìŠ¤íŠ¸ êµ¬ì„±
texts_to_embed = []
metadata_list = []

for item in raw_data:
    title = item["explanation_title"].strip()
    question = item["question"].strip()

    if item["context"].startswith("[IMAGE:"):
        # ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¬¸í•­
        context_part = item["context_explanation"].strip()
    else:
        # ğŸ“„ í…ìŠ¤íŠ¸ ë¬¸í•­
        context_part = item["context"].strip()

    embedding_text = f"{title}\n{context_part}\n{question}"
    texts_to_embed.append(embedding_text)
    metadata_list.append(item)

print(f"âœ… ì´ {len(texts_to_embed)}ê°œ ë¬¸í•­ ì„ë² ë”© ì¤€ë¹„ ì™„ë£Œ!")

# 3. ëª¨ë¸ ë¡œë”© & ì„ë² ë”©
print(f"ğŸ” ëª¨ë¸ ë¡œë”© ì¤‘: {MODEL_NAME}")
model = SentenceTransformer(MODEL_NAME)
embeddings = model.encode(texts_to_embed, convert_to_numpy=True)
dimension = embeddings.shape[1]

# 4. FAISS ì¸ë±ìŠ¤ ì €ì¥
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)
faiss.write_index(index, INDEX_PATH)
print(f"ğŸ“¦ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ â†’ {INDEX_PATH}")

# 5. ë©”íƒ€ë°ì´í„° ì €ì¥
with open(META_PATH, "wb") as f:
    pickle.dump(metadata_list, f)
print(f"ğŸ“ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ â†’ {META_PATH}")
