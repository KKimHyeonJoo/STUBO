import pickle
import faiss
import os
from sentence_transformers import SentenceTransformer
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document
from openai import OpenAI  # ìµœì‹  ë°©ì‹
from typing import Dict

# ìµœì‹  openai í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key="OPENAPI_KEY")
class InMemoryDocstore:
    def __init__(self, _dict: Dict[int, Document]):
        self._dict = _dict

    def search(self, search: int) -> Document:
        return self._dict[search]

    def add(self, texts: Dict[int, Document]) -> None:
        self._dict.update(texts)

    def delete(self, ids: list) -> None:
        for i in ids:
            self._dict.pop(i, None)

# Hugging Face embedding ëª¨ë¸ ì„¤ì •
MODEL_NAME = "jhgan/ko-sbert-nli"
embedding = HuggingFaceEmbeddings(model_name=MODEL_NAME)
model = SentenceTransformer(MODEL_NAME)

# FAISS vectorstore ë¡œë”©
VECTOR_DIR = "./pipeline/vectorstore_kosbert"
INDEX_PATH = f"{VECTOR_DIR}/index.faiss"
META_PATH = f"{VECTOR_DIR}/questions_metadata.pkl"
index = faiss.read_index(INDEX_PATH)
with open(META_PATH, "rb") as f:
    metadata = pickle.load(f)

# ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
docs = []
for m in metadata:
    title = m["explanation_title"].strip()
    question = m["question"].strip()
    if m["context"].startswith("[IMAGE:"):
        context_part = m["context_explanation"].strip()
    else:
        context_part = m["context"].strip()
    full_text = f"{title}\n{context_part}\n{question}"
    docs.append(Document(page_content=full_text, metadata=m))

# dense_k5 retriever êµ¬ì„±
docstore = InMemoryDocstore({i: doc for i, doc in enumerate(docs)})
index_to_docstore_id = {i: i for i in range(len(docs))}
vectorstore = FAISS(
    embedding_function=embedding,
    index=index,
    docstore=docstore,
    index_to_docstore_id=index_to_docstore_id,
)
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# GPT-4o í˜¸ì¶œ í•¨ìˆ˜
def query_gpt4o(question: str):
    relevant_docs = retriever.invoke(question)
    context = "\n\n".join([f"ë¬¸ì„œ {i+1}:\n{doc.page_content}" for i, doc in enumerate(relevant_docs)])
    prompt = (
        "ì•„ë˜ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•˜ê³  ê°„ê²°í•œ ë‹µë³€ì„ ìƒì„±í•´ì¤˜.\n\n"
        f"{context}\n\nì§ˆë¬¸: {question}\në‹µë³€:"
    )

    # ìµœì‹  ë°©ì‹ìœ¼ë¡œ GPT-4o í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ëŠ” ìœ¤ë¦¬ ì„ ìƒë‹˜ì´ì•¼."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
    )
    return response.choices[0].message.content.strip()

# ì˜ˆì‹œ ì‹¤í–‰
if __name__ == "__main__":
    q = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    answer = query_gpt4o(q)
    print("\nğŸ§  GPT-4oì˜ ë‹µë³€:\n")
    print(answer)
