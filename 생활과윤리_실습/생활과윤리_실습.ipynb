{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 패키지 설치 및 환경설정, 모듈 로드"
      ],
      "metadata": {
        "id": "2YvkG4BkB92q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnHySiNZjcAB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IB5R1lSj1RE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%pip install \"unstructured[pdf]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VSiDOs-lCay"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ose1zJ1VSKvw"
      },
      "outputs": [],
      "source": [
        "%pip install huggingface_hub[hf_xet]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_huggingface"
      ],
      "metadata": {
        "id": "SVFbSx2MEIXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U langchain-community"
      ],
      "metadata": {
        "id": "0PIOlUXBCLOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "raEHl3YYCHIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os"
      ],
      "metadata": {
        "id": "iFjVtuQ3CU-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "Ah4adfecCu3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from langchain.schema import Document\n",
        "from langchain.vectorstores import FAISS\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "shoKdSC1Cwvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. PDF 업로드 및 이미지 저장"
      ],
      "metadata": {
        "id": "ZaXqbmY-CZ2e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjoqJihfjYGV",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# 업로드된 PDF 경로\n",
        "pdf_path = \"/content/drive/MyDrive/EBS 2026학년도 수능특강 사회탐구영역 생활과 윤리(교사용).pdf\"\n",
        "\n",
        "# 이미지 저장 폴더\n",
        "image_output_dir = \"/content/drive/MyDrive/output_images\"\n",
        "os.makedirs(image_output_dir, exist_ok=True)\n",
        "\n",
        "# PDF에서 텍스트 및 이미지 추출\n",
        "elements = partition_pdf(\n",
        "    filename=pdf_path,\n",
        "    extract_images_in_pdf=True,\n",
        "    infer_table_structure=True,\n",
        "\n",
        "\n",
        "    chunking_strategy=\"by_title\",\n",
        "    max_characters=4000,\n",
        "    new_after_n_chars=3800,\n",
        "    combine_text_under_n_chars=2000,\n",
        "    pdf_image_output_dir_path=image_output_dir,\n",
        ")\n",
        "\n",
        "# 일부 요소 출력 확인\n",
        "for elem in elements[:5]:\n",
        "    print(type(elem), \"\\n\", elem, \"\\n---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장\n",
        "with open(\"elements.pkl\", \"wb\") as f:\n",
        "    pickle.dump(elements, f)"
      ],
      "metadata": {
        "id": "K5hZAHPBFebe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불러오기\n",
        "with open(\"/content/drive/MyDrive/elements.pkl\", \"rb\") as f:\n",
        "    elements = pickle.load(f)"
      ],
      "metadata": {
        "id": "oCKo-E4K5pUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBpAjddWxf5X"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "엑셀 파일로 저장\n",
        "\n",
        "import shutil\n",
        "\n",
        "folder_path = '/content/figures'\n",
        "output_zip = '/content/figures.zip'\n",
        "\n",
        "shutil.make_archive(output_zip.replace('.zip', ''), 'zip', folder_path)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 실습 실행"
      ],
      "metadata": {
        "id": "x9TkmkIDC1l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 이미지 경로들 가져오기\n",
        "image_paths = [os.path.join(image_output_dir, f) for f in os.listdir(image_output_dir) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]"
      ],
      "metadata": {
        "id": "yspGpbBjl_Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 텍스트 추출\n",
        "texts= [el.text for el in elements if el.text and el.text.strip() != \"\"]"
      ],
      "metadata": {
        "id": "Bc9PDmH7DHP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 텍스트 임베딩: BGE-M3 (수능특강처럼 텍스트가 긴 경우 BAAI/bge-m3 사용)\n",
        "bge_tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
        "bge_model = AutoModel.from_pretrained(\"BAAI/bge-m3\")\n",
        "\n",
        "# 이미지/텍스트 임베딩: CLIP\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ],
      "metadata": {
        "id": "b-yNpxQ277ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_text_bge(text):\n",
        "    inputs = bge_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=8192)\n",
        "    with torch.no_grad():\n",
        "        outputs = bge_model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0].cpu().numpy()[0]\n",
        "\n",
        "def embed_image_clip(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = clip_model.get_image_features(**inputs)\n",
        "    return outputs[0].cpu().numpy()"
      ],
      "metadata": {
        "id": "5apxiC4U8BJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. DummyEmbeddingFunction 선언\n",
        "\n",
        "class DummyEmbeddingFunction:\n",
        "    def __init__(self, vectors):\n",
        "        self.vectors = vectors\n",
        "        self.i = 0\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        results = self.vectors[self.i : self.i + len(texts)]\n",
        "        self.i += len(texts)\n",
        "        return results\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        raise NotImplementedError(\"Query embedding은 지원하지 않습니다.\")"
      ],
      "metadata": {
        "id": "ghpQK3Hh7kHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. docs, vectors 선언\n",
        "\n",
        "# 텍스트 리스트\n",
        "text_docs = [Document(page_content=t) for t in texts]\n",
        "text_vectors = np.array([embed_text_bge(t) for t in texts]).astype(\"float32\")\n",
        "\n",
        "# 이미지 경로 리스트\n",
        "image_docs = [Document(page_content=\"Image\", metadata={\"image_path\": path}) for path in image_paths]\n",
        "image_vectors = np.array([embed_image_clip(doc.metadata[\"image_path\"]) for doc in image_docs]).astype(\"float32\")"
      ],
      "metadata": {
        "id": "k_LjGHTs8JW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "img_save_path = \"/content/drive/MyDrive/img_text_embeddings.pkl\"  # 원하는 경로로 지정\n",
        "\n",
        "with open(img_save_path, \"wb\") as f:\n",
        "    pickle.dump({\n",
        "        \"documents\": image_docs,\n",
        "        \"vectors\": image_vectors,\n",
        "    }, f)\n",
        "\n",
        "print(f\"✅ 저장 완료: {img_save_path}\")\n",
        "\n",
        "\n",
        "txt_save_path = \"/content/drive/MyDrive/text_embeddings.pkl\"  # 원하는 경로로 지정\n",
        "\n",
        "with open(save_path, \"wb\") as f:\n",
        "    pickle.dump({\n",
        "        \"documents\": text_docs,\n",
        "        \"vectors\": text_vectors,\n",
        "    }, f)\n",
        "\n",
        "print(f\"✅ 저장 완료: {txt_save_path}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "msdmYrCxD6Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. VectorStore 선언\n",
        "\n",
        "# 텍스트 벡터스토어\n",
        "text_embedding_fn = DummyEmbeddingFunction(text_vectors)\n",
        "vectorstore_text = FAISS.from_documents(\n",
        "    documents=text_docs,\n",
        "    embedding=text_embedding_fn\n",
        ")\n",
        "\n",
        "# 이미지 벡터스토어\n",
        "image_embedding_fn = DummyEmbeddingFunction(image_vectors)\n",
        "vectorstore_image = FAISS.from_documents(\n",
        "    documents=image_docs,\n",
        "    embedding=image_embedding_fn\n",
        ")"
      ],
      "metadata": {
        "id": "nqBr7KGf7uGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 벡터스토어 저장\n",
        "vectorstore_image.save_local(\"/content/drive/MyDrive/vectorstore_text\")\n",
        "vectorstore_text.save_local(\"/content/drive/MyDrive/vectorstore_image\")\n",
        "\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.embeddings.base import Embeddings\n",
        "\n",
        "# 벡터스토어 로드\n",
        "class DummyEmbedding(Embeddings):\n",
        "    def embed_documents(self, texts): return []\n",
        "    def embed_query(self, text): return []\n",
        "\n",
        "vectorstore_text = FAISS.load_local(\n",
        "    folder_path=\"/content/drive/MyDrive/vectorstore_text\",\n",
        "    embeddings=DummyEmbedding()\n",
        ")\n",
        "\n",
        "vectorstore_image = FAISS.load_local(\n",
        "    folder_path=\"/content/drive/MyDrive/vectorstore_image\",\n",
        "    embeddings=DummyEmbedding()\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "id": "HIk44tdsKmiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. unified_search\n",
        "\n",
        "def unified_search(query, top_k=3):\n",
        "    # 텍스트용 BGE-M3 임베딩\n",
        "    bge_vector = embed_text_bge(query)\n",
        "    text_results = vectorstore_text.similarity_search_by_vector(bge_vector, k=top_k)\n",
        "\n",
        "    # 이미지 검색용 CLIP 텍스트 임베딩\n",
        "    clip_inputs = clip_processor(text=[query], return_tensors=\"pt\", padding=True)\n",
        "    with torch.no_grad():\n",
        "        clip_vector = clip_model.get_text_features(**clip_inputs)[0].cpu().numpy()\n",
        "    image_results = vectorstore_image.similarity_search_by_vector(clip_vector, k=top_k)\n",
        "\n",
        "    return {\n",
        "        \"text_results\": text_results,\n",
        "        \"image_results\": image_results\n",
        "    }"
      ],
      "metadata": {
        "id": "KQA7By-75Fba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 활용"
      ],
      "metadata": {
        "id": "y4iUnwafD0Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"행복에 대한 윤리적 관점\"\n",
        "results = unified_search(query)\n",
        "\n",
        "print(\"📘 텍스트 검색 결과:\")\n",
        "for r in results[\"text_results\"]:\n",
        "    print(\"-\", r.page_content[:100])\n",
        "\n",
        "print(\"\\n🖼 이미지 검색 결과:\")\n",
        "for r in results[\"image_results\"]:\n",
        "    print(\"-\", r.metadata.get(\"image_path\", \"경로 없음\"))"
      ],
      "metadata": {
        "id": "gQGzhmPl5IcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"석가모니의 주장\"\n",
        "results = unified_search(query, 5)\n",
        "\n",
        "print(\"📘 텍스트 검색 결과:\")\n",
        "for r in results[\"text_results\"]:\n",
        "    print(\"-\", r.page_content[:1000])\n",
        "\n",
        "print(\"\\n🖼 이미지 검색 결과:\")\n",
        "for r in results[\"image_results\"]:\n",
        "    print(\"-\", r.metadata.get(\"image_path\", \"경로 없음\"))"
      ],
      "metadata": {
        "id": "xPA2esXkBqT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. retriever 활용"
      ],
      "metadata": {
        "id": "G6LokMvIEb3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_text = vectorstore_text.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "retriever_image = vectorstore_image.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "DK61b9wL0sTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import BaseRetriever, Document\n",
        "from typing import List\n",
        "from pydantic import PrivateAttr\n",
        "import torch\n",
        "\n",
        "class UnifiedMultiModalRetriever(BaseRetriever):\n",
        "    _retriever_text: Any = PrivateAttr()\n",
        "    _retriever_image: Any = PrivateAttr()\n",
        "\n",
        "    def __init__(self, retriever_text, retriever_image):\n",
        "        super().__init__()\n",
        "        self._retriever_text = retriever_text\n",
        "        self._retriever_image = retriever_image\n",
        "\n",
        "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        # 텍스트 임베딩 → 텍스트 검색\n",
        "        bge_vector = embed_text_bge(query)\n",
        "        text_results = vectorstore_text.similarity_search_by_vector(bge_vector, k=3)\n",
        "\n",
        "        # CLIP 임베딩 → 이미지 검색\n",
        "        clip_inputs = clip_processor(text=[query], return_tensors=\"pt\", padding=True)\n",
        "        with torch.no_grad():\n",
        "            clip_vector = clip_model.get_text_features(**clip_inputs)[0].cpu().numpy()\n",
        "        image_results = vectorstore_image.similarity_search_by_vector(clip_vector, k=3)\n",
        "\n",
        "        return text_results + image_results"
      ],
      "metadata": {
        "id": "PfqtMcyANopY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = UnifiedMultiModalRetriever(retriever_text, retriever_image)\n",
        "\n",
        "results = retriever.get_relevant_documents(\"프롬의 주장은 뭘까?\")\n",
        "\n",
        "for doc in results:\n",
        "    if \"image_path\" in doc.metadata:\n",
        "        print(\"🖼 이미지:\", doc.metadata[\"image_path\"])\n",
        "    else:\n",
        "        print(\"📘 텍스트:\", doc.page_content[:1000])"
      ],
      "metadata": {
        "id": "G2AKN1U3Elke"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}