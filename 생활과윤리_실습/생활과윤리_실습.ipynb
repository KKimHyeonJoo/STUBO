{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° í™˜ê²½ì„¤ì •, ëª¨ë“ˆ ë¡œë“œ"
      ],
      "metadata": {
        "id": "2YvkG4BkB92q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnHySiNZjcAB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IB5R1lSj1RE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%pip install \"unstructured[pdf]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VSiDOs-lCay"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ose1zJ1VSKvw"
      },
      "outputs": [],
      "source": [
        "%pip install huggingface_hub[hf_xet]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_huggingface"
      ],
      "metadata": {
        "id": "SVFbSx2MEIXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U langchain-community"
      ],
      "metadata": {
        "id": "0PIOlUXBCLOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "raEHl3YYCHIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os"
      ],
      "metadata": {
        "id": "iFjVtuQ3CU-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "Ah4adfecCu3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from langchain.schema import Document\n",
        "from langchain.vectorstores import FAISS\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "shoKdSC1Cwvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. PDF ì—…ë¡œë“œ ë° ì´ë¯¸ì§€ ì €ì¥"
      ],
      "metadata": {
        "id": "ZaXqbmY-CZ2e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjoqJihfjYGV",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# ì—…ë¡œë“œëœ PDF ê²½ë¡œ\n",
        "pdf_path = \"/content/drive/MyDrive/EBS 2026á„’á…¡á†¨á„‚á…§á†«á„ƒá…© á„‰á…®á„‚á…³á†¼á„á…³á†¨á„€á…¡á†¼ á„‰á…¡á„’á…¬á„á…¡á†·á„€á…®á„‹á…§á†¼á„‹á…§á†¨ ìƒí™œê³¼ ìœ¤ë¦¬(á„€á…­á„‰á…¡á„‹á…­á†¼).pdf\"\n",
        "\n",
        "# ì´ë¯¸ì§€ ì €ì¥ í´ë”\n",
        "image_output_dir = \"/content/drive/MyDrive/output_images\"\n",
        "os.makedirs(image_output_dir, exist_ok=True)\n",
        "\n",
        "# PDFì—ì„œ í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ì¶”ì¶œ\n",
        "elements = partition_pdf(\n",
        "    filename=pdf_path,\n",
        "    extract_images_in_pdf=True,\n",
        "    infer_table_structure=True,\n",
        "\n",
        "\n",
        "    chunking_strategy=\"by_title\",\n",
        "    max_characters=4000,\n",
        "    new_after_n_chars=3800,\n",
        "    combine_text_under_n_chars=2000,\n",
        "    pdf_image_output_dir_path=image_output_dir,\n",
        ")\n",
        "\n",
        "# ì¼ë¶€ ìš”ì†Œ ì¶œë ¥ í™•ì¸\n",
        "for elem in elements[:5]:\n",
        "    print(type(elem), \"\\n\", elem, \"\\n---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì €ì¥\n",
        "with open(\"elements.pkl\", \"wb\") as f:\n",
        "    pickle.dump(elements, f)"
      ],
      "metadata": {
        "id": "K5hZAHPBFebe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "with open(\"/content/drive/MyDrive/elements.pkl\", \"rb\") as f:\n",
        "    elements = pickle.load(f)"
      ],
      "metadata": {
        "id": "oCKo-E4K5pUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBpAjddWxf5X"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥\n",
        "\n",
        "import shutil\n",
        "\n",
        "folder_path = '/content/figures'\n",
        "output_zip = '/content/figures.zip'\n",
        "\n",
        "shutil.make_archive(output_zip.replace('.zip', ''), 'zip', folder_path)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. ì‹¤ìŠµ ì‹¤í–‰"
      ],
      "metadata": {
        "id": "x9TkmkIDC1l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ì´ë¯¸ì§€ ê²½ë¡œë“¤ ê°€ì ¸ì˜¤ê¸°\n",
        "image_paths = [os.path.join(image_output_dir, f) for f in os.listdir(image_output_dir) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]"
      ],
      "metadata": {
        "id": "yspGpbBjl_Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "texts= [el.text for el in elements if el.text and el.text.strip() != \"\"]"
      ],
      "metadata": {
        "id": "Bc9PDmH7DHP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. í…ìŠ¤íŠ¸ ì„ë² ë”©: BGE-M3 (ìˆ˜ëŠ¥íŠ¹ê°•ì²˜ëŸ¼ í…ìŠ¤íŠ¸ê°€ ê¸´ ê²½ìš° BAAI/bge-m3 ì‚¬ìš©)\n",
        "bge_tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
        "bge_model = AutoModel.from_pretrained(\"BAAI/bge-m3\")\n",
        "\n",
        "# ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ ì„ë² ë”©: CLIP\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ],
      "metadata": {
        "id": "b-yNpxQ277ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_text_bge(text):\n",
        "    inputs = bge_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=8192)\n",
        "    with torch.no_grad():\n",
        "        outputs = bge_model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0].cpu().numpy()[0]\n",
        "\n",
        "def embed_image_clip(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = clip_model.get_image_features(**inputs)\n",
        "    return outputs[0].cpu().numpy()"
      ],
      "metadata": {
        "id": "5apxiC4U8BJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. DummyEmbeddingFunction ì„ ì–¸\n",
        "\n",
        "class DummyEmbeddingFunction:\n",
        "    def __init__(self, vectors):\n",
        "        self.vectors = vectors\n",
        "        self.i = 0\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        results = self.vectors[self.i : self.i + len(texts)]\n",
        "        self.i += len(texts)\n",
        "        return results\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        raise NotImplementedError(\"Query embeddingì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "id": "ghpQK3Hh7kHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. docs, vectors ì„ ì–¸\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
        "text_docs = [Document(page_content=t) for t in texts]\n",
        "text_vectors = np.array([embed_text_bge(t) for t in texts]).astype(\"float32\")\n",
        "\n",
        "# ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "image_docs = [Document(page_content=\"Image\", metadata={\"image_path\": path}) for path in image_paths]\n",
        "image_vectors = np.array([embed_image_clip(doc.metadata[\"image_path\"]) for doc in image_docs]).astype(\"float32\")"
      ],
      "metadata": {
        "id": "k_LjGHTs8JW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "img_save_path = \"/content/drive/MyDrive/img_text_embeddings.pkl\"  # ì›í•˜ëŠ” ê²½ë¡œë¡œ ì§€ì •\n",
        "\n",
        "with open(img_save_path, \"wb\") as f:\n",
        "    pickle.dump({\n",
        "        \"documents\": image_docs,\n",
        "        \"vectors\": image_vectors,\n",
        "    }, f)\n",
        "\n",
        "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {img_save_path}\")\n",
        "\n",
        "\n",
        "txt_save_path = \"/content/drive/MyDrive/text_embeddings.pkl\"  # ì›í•˜ëŠ” ê²½ë¡œë¡œ ì§€ì •\n",
        "\n",
        "with open(save_path, \"wb\") as f:\n",
        "    pickle.dump({\n",
        "        \"documents\": text_docs,\n",
        "        \"vectors\": text_vectors,\n",
        "    }, f)\n",
        "\n",
        "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {txt_save_path}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "msdmYrCxD6Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. VectorStore ì„ ì–¸\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ë²¡í„°ìŠ¤í† ì–´\n",
        "text_embedding_fn = DummyEmbeddingFunction(text_vectors)\n",
        "vectorstore_text = FAISS.from_documents(\n",
        "    documents=text_docs,\n",
        "    embedding=text_embedding_fn\n",
        ")\n",
        "\n",
        "# ì´ë¯¸ì§€ ë²¡í„°ìŠ¤í† ì–´\n",
        "image_embedding_fn = DummyEmbeddingFunction(image_vectors)\n",
        "vectorstore_image = FAISS.from_documents(\n",
        "    documents=image_docs,\n",
        "    embedding=image_embedding_fn\n",
        ")"
      ],
      "metadata": {
        "id": "nqBr7KGf7uGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# ë²¡í„°ìŠ¤í† ì–´ ì €ì¥\n",
        "vectorstore_image.save_local(\"/content/drive/MyDrive/vectorstore_text\")\n",
        "vectorstore_text.save_local(\"/content/drive/MyDrive/vectorstore_image\")\n",
        "\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.embeddings.base import Embeddings\n",
        "\n",
        "# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ\n",
        "class DummyEmbedding(Embeddings):\n",
        "    def embed_documents(self, texts): return []\n",
        "    def embed_query(self, text): return []\n",
        "\n",
        "vectorstore_text = FAISS.load_local(\n",
        "    folder_path=\"/content/drive/MyDrive/vectorstore_text\",\n",
        "    embeddings=DummyEmbedding()\n",
        ")\n",
        "\n",
        "vectorstore_image = FAISS.load_local(\n",
        "    folder_path=\"/content/drive/MyDrive/vectorstore_image\",\n",
        "    embeddings=DummyEmbedding()\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "id": "HIk44tdsKmiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. unified_search\n",
        "\n",
        "def unified_search(query, top_k=3):\n",
        "    # í…ìŠ¤íŠ¸ìš© BGE-M3 ì„ë² ë”©\n",
        "    bge_vector = embed_text_bge(query)\n",
        "    text_results = vectorstore_text.similarity_search_by_vector(bge_vector, k=top_k)\n",
        "\n",
        "    # ì´ë¯¸ì§€ ê²€ìƒ‰ìš© CLIP í…ìŠ¤íŠ¸ ì„ë² ë”©\n",
        "    clip_inputs = clip_processor(text=[query], return_tensors=\"pt\", padding=True)\n",
        "    with torch.no_grad():\n",
        "        clip_vector = clip_model.get_text_features(**clip_inputs)[0].cpu().numpy()\n",
        "    image_results = vectorstore_image.similarity_search_by_vector(clip_vector, k=top_k)\n",
        "\n",
        "    return {\n",
        "        \"text_results\": text_results,\n",
        "        \"image_results\": image_results\n",
        "    }"
      ],
      "metadata": {
        "id": "KQA7By-75Fba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. í™œìš©"
      ],
      "metadata": {
        "id": "y4iUnwafD0Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"í–‰ë³µì— ëŒ€í•œ ìœ¤ë¦¬ì  ê´€ì \"\n",
        "results = unified_search(query)\n",
        "\n",
        "print(\"ğŸ“˜ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼:\")\n",
        "for r in results[\"text_results\"]:\n",
        "    print(\"-\", r.page_content[:100])\n",
        "\n",
        "print(\"\\nğŸ–¼ ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼:\")\n",
        "for r in results[\"image_results\"]:\n",
        "    print(\"-\", r.metadata.get(\"image_path\", \"ê²½ë¡œ ì—†ìŒ\"))"
      ],
      "metadata": {
        "id": "gQGzhmPl5IcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"ì„ê°€ëª¨ë‹ˆì˜ ì£¼ì¥\"\n",
        "results = unified_search(query, 5)\n",
        "\n",
        "print(\"ğŸ“˜ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼:\")\n",
        "for r in results[\"text_results\"]:\n",
        "    print(\"-\", r.page_content[:1000])\n",
        "\n",
        "print(\"\\nğŸ–¼ ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼:\")\n",
        "for r in results[\"image_results\"]:\n",
        "    print(\"-\", r.metadata.get(\"image_path\", \"ê²½ë¡œ ì—†ìŒ\"))"
      ],
      "metadata": {
        "id": "xPA2esXkBqT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. retriever í™œìš©"
      ],
      "metadata": {
        "id": "G6LokMvIEb3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_text = vectorstore_text.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "retriever_image = vectorstore_image.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "DK61b9wL0sTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import BaseRetriever, Document\n",
        "from typing import List\n",
        "from pydantic import PrivateAttr\n",
        "import torch\n",
        "\n",
        "class UnifiedMultiModalRetriever(BaseRetriever):\n",
        "    _retriever_text: Any = PrivateAttr()\n",
        "    _retriever_image: Any = PrivateAttr()\n",
        "\n",
        "    def __init__(self, retriever_text, retriever_image):\n",
        "        super().__init__()\n",
        "        self._retriever_text = retriever_text\n",
        "        self._retriever_image = retriever_image\n",
        "\n",
        "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        # í…ìŠ¤íŠ¸ ì„ë² ë”© â†’ í…ìŠ¤íŠ¸ ê²€ìƒ‰\n",
        "        bge_vector = embed_text_bge(query)\n",
        "        text_results = vectorstore_text.similarity_search_by_vector(bge_vector, k=3)\n",
        "\n",
        "        # CLIP ì„ë² ë”© â†’ ì´ë¯¸ì§€ ê²€ìƒ‰\n",
        "        clip_inputs = clip_processor(text=[query], return_tensors=\"pt\", padding=True)\n",
        "        with torch.no_grad():\n",
        "            clip_vector = clip_model.get_text_features(**clip_inputs)[0].cpu().numpy()\n",
        "        image_results = vectorstore_image.similarity_search_by_vector(clip_vector, k=3)\n",
        "\n",
        "        return text_results + image_results"
      ],
      "metadata": {
        "id": "PfqtMcyANopY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = UnifiedMultiModalRetriever(retriever_text, retriever_image)\n",
        "\n",
        "results = retriever.get_relevant_documents(\"í”„ë¡¬ì˜ ì£¼ì¥ì€ ë­˜ê¹Œ?\")\n",
        "\n",
        "for doc in results:\n",
        "    if \"image_path\" in doc.metadata:\n",
        "        print(\"ğŸ–¼ ì´ë¯¸ì§€:\", doc.metadata[\"image_path\"])\n",
        "    else:\n",
        "        print(\"ğŸ“˜ í…ìŠ¤íŠ¸:\", doc.page_content[:1000])"
      ],
      "metadata": {
        "id": "G2AKN1U3Elke"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}