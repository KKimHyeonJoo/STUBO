import os
os.environ["OPENAI_API_KEY"] = "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"

import base64
from PIL import Image
from openai import OpenAI


"""## Easy OCR"""

import os
import re
import json
import cv2
import numpy as np
import unicodedata
import easyocr
from openai import OpenAI
from PIL import Image

# âœ… ì„¤ì •
image_dir = "/content/drive/MyDrive/classified_images/ë¹„ë¬¸í•™"
client = OpenAI()
reader = easyocr.Reader(['ko', 'en'], gpu=True)

# âœ… ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
def normalize_filename(fn):
    return unicodedata.normalize('NFC', fn)

def extract_text_with_underlines(image_path):
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"ì´ë¯¸ì§€ ê²½ë¡œ ì—†ìŒ: {image_path}")
    
    # PIL ë¡œë“œ í›„ numpy ë°°ì—´ë¡œ ë³€í™˜
    pil_img = Image.open(image_path).convert("RGB")
    img = np.array(pil_img)

    # OpenCVì™€ í˜¸í™˜ë˜ë„ë¡ BGRë¡œ ë³€í™˜
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    results = reader.readtext(gray, detail=True)
    full_text = " ".join([text for (_, text, _) in results])
    return re.sub(r'\b1[\.\)]', 'â‘ ', full_text)\
             .replace('2.', 'â‘¡')\
             .replace('3.', 'â‘¢')\
             .replace('4.', 'â‘£')\
             .replace('5.', 'â‘¤')\
             .strip()


# âœ… GPT í”„ë¡¬í”„íŠ¸
text_prompt = '''
ë‹¤ìŒì€ êµ­ì–´ ë¹„ë¬¸í•™ ë¬¸ì œì…ë‹ˆë‹¤. ì§€ë¬¸ê³¼ ë¬¸ì œ(ì„ íƒì§€ í¬í•¨)ë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:

1. ì§ˆë¬¸ ì¡°ê±´ì„ ì •í™•íˆ ë°˜ì˜í•´ ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”.
2. ë°˜ë“œì‹œ â‘ ~â‘¤ ì¤‘ í•˜ë‚˜ë§Œ ê³¨ë¼ [ì •ë‹µ] â‘¢ í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.
3. ì§€ë¬¸ì— ê·¼ê±°í•œ í•´ì„¤ì„ [í•´ì„¤]ë¡œ 3~5ë¬¸ì¥ ì“°ì„¸ìš”.

[ì§€ë¬¸]
{passage}

[ë¬¸ì œ]
{question}

ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:

[ì •ë‹µ] â‘¢
[í•´ì„¤] â€¦ (ì—¬ê¸°ì— ê·¼ê±° ì„¤ëª…)

'''

# âœ… GPT ì‹¤í–‰ ë° íŒŒì‹±
def ask_gpt(prompt_text):
    resp = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt_text}],
        temperature=0.3
    )
    return resp.choices[0].message.content

def parse_gpt_output(output):
    a = re.search(r'\[ì •ë‹µ\]\s*([â‘ -â‘¤])', output)
    e = re.search(r'\[í•´ì„¤\](.*)', output, re.DOTALL)
    return (a.group(1) if a else None), (e.group(1).strip() if e else "")

# âœ… ë§¤í•‘
def get_mapping(year, month):
    special = (year, month) in [(2024, "06"), (2024, "09"), (2024, "ìˆ˜ëŠ¥"), (2025, "06"), (2025, "09")]
    return {
        "p1": [1, 2, 3],
        "p2": list(range(4, 8)) if special else list(range(4, 10)),
        "p3": list(range(8, 12)) if special else list(range(10, 14)),
        "p4": list(range(12, 18)) if special else list(range(14, 18))
    }

def solve_question_with_images(passage_img_path, question_img_path):
    # ì´ë¯¸ì§€ ê²½ë¡œ ìœ íš¨ì„± í™•ì¸
    if not os.path.exists(passage_img_path):
        print(f"âŒ ì§€ë¬¸ ì´ë¯¸ì§€ ì—†ìŒ: {passage_img_path}")
        return
    if not os.path.exists(question_img_path):
        print(f"âŒ ë¬¸ì œ ì´ë¯¸ì§€ ì—†ìŒ: {question_img_path}")
        return

    # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
    passage_text = extract_text_with_underlines(passage_img_path)
    question_text = extract_text_with_underlines(question_img_path)

    # GPT í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ìš”ì²­
    prompt = text_prompt.format(passage=passage_text, question=question_text)

    try:
        gpt_output = ask_gpt(prompt)
        print("\nğŸ“— GPT ì‘ë‹µ:")
        print(gpt_output)
    except Exception as e:
        print(f"âš ï¸ GPT ì‹¤íŒ¨: {e}")

solve_question_with_images(
    r"C:/Users/user/STUBO/ì–¸ì–´ì™€ë§¤ì²´/output_images/2024-ìˆ˜ëŠ¥-ì–¸ë§¤_35.png", # ì‚¬ìš©ì ì§ì ‘ ì…ë ¥
    r"C:/Users/user/STUBO/ì–¸ì–´ì™€ë§¤ì²´/output_images/2024-ìˆ˜ëŠ¥-ì–¸ë§¤_p9.png" # ì‚¬ìš©ì ì§ì ‘ ì…ë ¥
    
)